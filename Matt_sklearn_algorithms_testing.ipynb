{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Packages related to general operating system & warnings\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#Packages related to data importing, manipulation, exploratory data #analysis, data understanding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from termcolor import colored as cl # text customization\n",
    "#Packages related to data visualizaiton\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Setting plot sizes and type of plot\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.gray()\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa as tsa\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "# svm with class weight on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal number of Trnsactions are 284807\u001b[0m\n",
      "\u001b[1mNumber of Normal Transactions are 284315\u001b[0m\n",
      "\u001b[1mNumber of fraudulent Transactions are 492\u001b[0m\n",
      "\u001b[1mPercentage of fraud Transactions is 0.17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Total_transactions = len(data)\n",
    "normal = len(data[data.Class == 0])\n",
    "fraudulent = len(data[data.Class == 1])\n",
    "fraud_percentage = round(fraudulent/normal*100, 2)\n",
    "print(cl('Total number of Trnsactions are {}'.format(Total_transactions), attrs = ['bold']))\n",
    "print(cl('Number of Normal Transactions are {}'.format(normal), attrs = ['bold']))\n",
    "print(cl('Number of fraudulent Transactions are {}'.format(fraudulent), attrs = ['bold']))\n",
    "print(cl('Percentage of fraud Transactions is {}'.format(fraud_percentage), attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "amount = data['Amount'].values\n",
    "data['Amount'] = sc.fit_transform(amount.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n"
     ]
    }
   ],
   "source": [
    "data.drop(['Time'], axis=1, inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275663, 30)\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1).values\n",
    "y = data['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.999288989494457\n",
      "F1 score of the K-Nearest Neighbors model is 0.7949790794979079\n"
     ]
    }
   ],
   "source": [
    "n = 7\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
    "\n",
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression model is 0.9989552498694062\n",
      "F1 score of the Logistic Regression model is 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68772,    16],\n",
       "       [   56,    72]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)\n",
    "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
    "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)))\n",
    "confusion_matrix(y_test,lr_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Support Vector Machines model is 0.999318010331418\n",
      "F1 score of the Support Vector Machines model is 0.7813953488372093\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_yhat)))\n",
    "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_yhat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68785,     3],\n",
       "       [   44,    84]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,svm_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "svm_penalized = SVC(gamma='scale', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\meuli\\Desktop\\ML\\Credit_Card_Fraud_Detection\\Matt_sklearn_algorithms_testing.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/Credit_Card_Fraud_Detection/Matt_sklearn_algorithms_testing.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/Credit_Card_Fraud_Detection/Matt_sklearn_algorithms_testing.ipynb#ch0000020?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(svm_penalized, X_train, y_train, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1) # repeats 3?\n",
    "# evaluate model\n",
    "scores = cross_val_score(svm_penalized, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Support Vector Machines model is 0.9961547391026757\n",
      "F1 score of the Support Vector Machines model is 0.41758241758241754\n"
     ]
    }
   ],
   "source": [
    "svm_penalized.fit(X_train, y_train)\n",
    "svm_penalized_yhat = svm_penalized.predict(X_test)\n",
    "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_penalized_yhat)))\n",
    "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_penalized_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68556,   232],\n",
       "       [   33,    95]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,svm_penalized_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, svm_penalized_yhat)\n",
    "# summarize performance\n",
    "# print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "dt_yhat = DT.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, dt_yhat)))\n",
    "\n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, dt_yhat)))\n",
    "\n",
    "confusion_matrix(y_test,dt_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest model is 0.9991293748911718\n",
      "F1 score of the Random Forest model is 0.7222222222222223\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
    "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17b4c01959b763961e65029bfd8cfa288ed8d0492d779c607a82e02daf2d74ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
